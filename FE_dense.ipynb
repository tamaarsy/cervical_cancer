{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "#visual\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import scipy as sy\n",
    "from PIL import Image\n",
    "\n",
    "#file\n",
    "import shutil\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "#models\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "from skimage.feature import greycomatrix,greycoprops\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "\n",
    "train_image_mask= []\n",
    "train_label_mask = []\n",
    "\n",
    "for directory_path in glob.glob(\"../data/img_cyt_train/*\"):\n",
    "  label = directory_path.split(\"\\\\\")[-1]\n",
    "  #print()\n",
    "  for img_path in glob.glob(os.path.join(directory_path,\"*.bmp\")):\n",
    "    #print(img_path)\n",
    "    img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "    img = cv.resize(img,(SIZE,SIZE))\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "    train_image_mask.append(img)\n",
    "    train_label_mask.append(label)\n",
    "\n",
    "train_images_mask = np.array(train_image_mask)\n",
    "train_labels_mask = np.array(train_label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels_mask)\n",
    "train_label_endc_mask = le.transform(train_labels_mask)\n",
    "\n",
    "\n",
    "\n",
    "x_train_mask, y_train_mask = train_images_mask, train_label_endc_mask\n",
    "\n",
    "x_train_mask = x_train_mask/225\n",
    "\n",
    "np.savetxt('mask/DenseNet121/dense_label_train_mask.txt', y_train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:38:07.985145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (224,224) + (3,)\n",
    "base_model = tf.keras.applications.DenseNet121(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:38:15.753420: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 301056000 exceeds 10% of free system memory.\n",
      "2022-11-01 21:38:21.078921: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 32112640 exceeds 10% of free system memory.\n",
      "2022-11-01 21:38:21.212268: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 33269760 exceeds 10% of free system memory.\n",
      "2022-11-01 21:38:21.594344: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20070400 exceeds 10% of free system memory.\n",
      "2022-11-01 21:38:21.598944: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20070400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 66s 1s/step\n",
      "(500, 7, 7, 1024)\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[:500], batch_size=10)\n",
    "print(feature_extraction_mobile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/DenseNet121/DenseNet_pre_train1.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 45s 906ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[500:1000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/DenseNet121/DenseNet_pre_train2.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 46s 913ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[1000:1500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/DenseNet121/DenseNet_pre_train3.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 44s 875ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[1500:2000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/DenseNet121/DenseNet_pre_train4.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 50s 995ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[2000:2500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/DenseNet121/DenseNet_pre_train5.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 46s 913ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[2500:3000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/DenseNet121/DenseNet_pre_train6.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 90s 830ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1047, 50176)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[3000:], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/DenseNet121/DenseNet_pre_train7.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_DenseNet1 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train1.txt')\n",
    "dt_DenseNet2 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train2.txt')\n",
    "dt_DenseNet3 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train3.txt')\n",
    "dt_DenseNet4 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train4.txt')\n",
    "dt_DenseNet5 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train5.txt')\n",
    "dt_DenseNet6 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train6.txt')\n",
    "dt_DenseNet7 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train7.txt')\n",
    "\n",
    "DenseNet_full = [dt_DenseNet1,dt_DenseNet2,dt_DenseNet3,dt_DenseNet4,dt_DenseNet5,dt_DenseNet6,dt_DenseNet7]\n",
    "\n",
    "for i in DenseNet_full:print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concat = np.concatenate((dt_DenseNet1, dt_DenseNet2, dt_DenseNet3, dt_DenseNet4, dt_DenseNet5, dt_DenseNet6), axis=0)\n",
    "np.savetxt(\"mask/DenseNet121/densenet_full_data.txt\",train_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "\n",
    "train_image= []\n",
    "train_label = []\n",
    "\n",
    "for directory_path in glob.glob(\"../data/train/*\"):\n",
    "  label = directory_path.split(\"\\\\\")[-1]\n",
    "  #print()\n",
    "  for img_path in glob.glob(os.path.join(directory_path,\"*.bmp\")):\n",
    "    #print(img_path)\n",
    "    img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "    img = cv.resize(img,(SIZE,SIZE))\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "    train_image.append(img)\n",
    "    train_label.append(label)\n",
    "\n",
    "train_images = np.array(train_image)\n",
    "train_labels = np.array(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_label_endc = le.transform(train_labels)\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = train_images, train_label_endc\n",
    "\n",
    "x_train = x_train/225\n",
    "\n",
    "np.savetxt('nomask/DenseNet121/dense_label_train.txt', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 23:29:04.015488: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-16 23:29:04.015874: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 23:29:04.016712: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (224,224) + (3,)\n",
    "base_model = tf.keras.applications.DenseNet121(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 23:29:32.029536: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-01-16 23:29:32.058090: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2699905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7, 7, 1024)\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train[:500], batch_size=10)\n",
    "print(feature_extraction_mobile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/DenseNet121/DenseNet_pre_train1.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train[500:1000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"nomask/DenseNet121/DenseNet_pre_train2.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[1000:1500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"nomask/DenseNet121/DenseNet_pre_train3.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[1500:2000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"nomask/DenseNet121/DenseNet_pre_train4.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 50176)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[2000:2500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"nomask/DenseNet121/DenseNet_pre_train5.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[2500:3000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/DenseNet121/DenseNet_pre_train6.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_mobile = base_model.predict(x_train_mask[3000:], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/DenseNet121/DenseNet_pre_train7.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50176)\n",
      "(500, 50176)\n",
      "(500, 50176)\n",
      "(500, 50176)\n",
      "(500, 50176)\n",
      "(500, 50176)\n",
      "(34, 50176)\n"
     ]
    }
   ],
   "source": [
    "dt_DenseNet1 = np.loadtxt('nomask/DenseNet121/DenseNet_pre_train1.txt')\n",
    "dt_DenseNet2 = np.loadtxt('nomask/DenseNet121/DenseNet_pre_train2.txt')\n",
    "dt_DenseNet3 = np.loadtxt('nomask/DenseNet121/DenseNet_pre_train3.txt')\n",
    "dt_DenseNet4 = np.loadtxt('nomask/DenseNet121/DenseNet_pre_train4.txt')\n",
    "dt_DenseNet5 = np.loadtxt('nomask/DenseNet121/DenseNet_pre_train5.txt')\n",
    "dt_DenseNet6 = np.loadtxt('nomask/DenseNet121/DenseNet_pre_train6.txt')\n",
    "dt_DenseNet7 = np.loadtxt('nomask/DenseNet121/DenseNet_pre_train7.txt')\n",
    "\n",
    "DenseNet_full = [dt_DenseNet1,dt_DenseNet2,dt_DenseNet3,dt_DenseNet4,dt_DenseNet5,dt_DenseNet6,dt_DenseNet7]\n",
    "\n",
    "for i in DenseNet_full:print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3034 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "3029      4\n",
       "3030      4\n",
       "3031      4\n",
       "3032      4\n",
       "3033      4\n",
       "\n",
       "[3034 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.loadtxt('nomask/DenseNet121/dense_label_train_mask.txt')\n",
    "label = label.astype('int')\n",
    "label = pd.DataFrame(data=label, columns=['label'])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concat = np.concatenate((dt_DenseNet1, dt_DenseNet2, dt_DenseNet3, dt_DenseNet4, dt_DenseNet5, dt_DenseNet6,dt_DenseNet7), axis=0)\n",
    "df = pd.DataFrame(train_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,label], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.to_csv('nomask/DenseNet121/full_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "084adf559b79bdfd7aeb0eec694c5d5559086d7c1a3de819d43aa00129408237"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

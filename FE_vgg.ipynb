{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tama/.local/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "#visual\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import scipy as sy\n",
    "from PIL import Image\n",
    "\n",
    "#file\n",
    "import shutil\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "#models\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "from skimage.feature import greycomatrix,greycoprops\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "\n",
    "train_image_mask= []\n",
    "train_label_mask = []\n",
    "\n",
    "for directory_path in glob.glob(\"../data/img_cyt_train/*\"):\n",
    "  label = directory_path.split(\"\\\\\")[-1]\n",
    "  #print()\n",
    "  for img_path in glob.glob(os.path.join(directory_path,\"*.bmp\")):\n",
    "    #print(img_path)\n",
    "    img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "    img = cv.resize(img,(SIZE,SIZE))\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "    train_image_mask.append(img)\n",
    "    train_label_mask.append(label)\n",
    "\n",
    "train_images_mask = np.array(train_image_mask)\n",
    "train_labels_mask = np.array(train_label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels_mask)\n",
    "train_label_endc_mask = le.transform(train_labels_mask)\n",
    "\n",
    "\n",
    "\n",
    "x_train_mask, y_train_mask = train_images_mask, train_label_endc_mask\n",
    "\n",
    "x_train_mask = x_train_mask/225\n",
    "\n",
    "np.savetxt('mask/vgg/dense_label_train_mask.txt', y_train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 01:44:44.430247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "vgg16_model_mask = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE,SIZE,3))\n",
    "for layers in vgg16_model_mask.layers:\n",
    "            layers.trainable=False\n",
    "vgg16_model_mask.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 01:05:27.280932: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 393216000 exceeds 10% of free system memory.\n",
      "2022-11-02 01:05:34.465582: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 167772160 exceeds 10% of free system memory.\n",
      "2022-11-02 01:05:34.642578: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 167772160 exceeds 10% of free system memory.\n",
      "2022-11-02 01:05:35.750051: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 41943040 exceeds 10% of free system memory.\n",
      "2022-11-02 01:05:35.921930: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 83886080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/50 [=====>........................] - ETA: 2:21"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[:500], batch_size=10)\n",
    "print(feature_extraction_mobile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 62720)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/vgg/pre_train1.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 12s 247ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 62720)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[500:1000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/vgg/pre_train2.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 12s 247ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 62720)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[1000:1500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/vgg/pre_train3.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 12s 244ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 62720)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[1500:2000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/vgg/pre_train4.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 12s 247ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 62720)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[2000:2500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/vgg/pre_train5.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 11s 222ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 62720)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[2500:3000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/vgg/pre_train6.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 01:44:46.647411: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 823394304 exceeds 10% of free system memory.\n",
      "2022-11-02 01:44:54.092186: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 167772160 exceeds 10% of free system memory.\n",
      "2022-11-02 01:44:54.339198: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 167772160 exceeds 10% of free system memory.\n",
      "2022-11-02 01:44:54.994327: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 41943040 exceeds 10% of free system memory.\n",
      "2022-11-02 01:44:55.122249: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 83886080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 380s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1047, 32768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[3000:], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mask/vgg/pre_train7.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt_DenseNet1 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train1.txt')\n",
    "#dt_DenseNet2 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train2.txt')\n",
    "#dt_DenseNet3 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train3.txt')\n",
    "#dt_DenseNet4 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train4.txt')\n",
    "#dt_DenseNet5 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train5.txt')\n",
    "#dt_DenseNet6 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train6.txt')\n",
    "#dt_DenseNet7 = np.loadtxt('mask/DenseNet121/DenseNet_pre_train7.txt')\n",
    "\n",
    "#DenseNet_full = [dt_DenseNet1,dt_DenseNet2,dt_DenseNet3,dt_DenseNet4,dt_DenseNet5,dt_DenseNet6,dt_DenseNet7]\n",
    "\n",
    "#for i in DenseNet_full:print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_concat = np.concatenate((dt_DenseNet1, dt_DenseNet2, dt_DenseNet3, dt_DenseNet4, dt_DenseNet5, dt_DenseNet6), axis=0)\n",
    "#np.savetxt(\"mask/DenseNet121/densenet_full_data.txt\",train_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "\n",
    "train_image_mask= []\n",
    "train_label_mask = []\n",
    "\n",
    "for directory_path in glob.glob(\"../data/train/*\"):\n",
    "  label = directory_path.split(\"\\\\\")[-1]\n",
    "  #print()\n",
    "  for img_path in glob.glob(os.path.join(directory_path,\"*.bmp\")):\n",
    "    #print(img_path)\n",
    "    img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "    img = cv.resize(img,(SIZE,SIZE))\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "    train_image_mask.append(img)\n",
    "    train_label_mask.append(label)\n",
    "\n",
    "train_images_mask = np.array(train_image_mask)\n",
    "train_labels_mask = np.array(train_label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels_mask)\n",
    "train_label_endc_mask = le.transform(train_labels_mask)\n",
    "\n",
    "\n",
    "\n",
    "x_train_mask, y_train_mask = train_images_mask, train_label_endc_mask\n",
    "\n",
    "x_train_mask = x_train_mask/225\n",
    "\n",
    "np.savetxt('nomask/vgg/dense_label_train_mask.txt', y_train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 12:33:10.650123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "vgg16_model_mask = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE,SIZE,3))\n",
    "for layers in vgg16_model_mask.layers:\n",
    "            layers.trainable=False\n",
    "vgg16_model_mask.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 12:34:35.192319: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 393216000 exceeds 10% of free system memory.\n",
      "2023-01-17 12:34:36.315653: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 167772160 exceeds 10% of free system memory.\n",
      "2023-01-17 12:34:36.486285: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 167772160 exceeds 10% of free system memory.\n",
      "2023-01-17 12:34:37.076616: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 41943040 exceeds 10% of free system memory.\n",
      "2023-01-17 12:34:37.347542: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 83886080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 204s 4s/step\n",
      "(500, 8, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[:500], batch_size=10)\n",
    "print(feature_extraction_mobile.shape)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/vgg/pre_train1.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 202s 4s/step\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[500:1000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/vgg/pre_train2.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 246s 5s/step\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[1000:1500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/vgg/pre_train3.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 207s 4s/step\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[1500:2000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/vgg/pre_train4.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 204s 4s/step\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[2000:2500], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/vgg/pre_train5.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 209s 4s/step\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[2500:3000], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/vgg/pre_train6.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 3s/step\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_mobile = vgg16_model_mask.predict(x_train_mask[3000:], batch_size=10)\n",
    "feature_extraction_mobile = feature_extraction_mobile.reshape(feature_extraction_mobile.shape[0],-1)\n",
    "feature_extraction_mobile.shape\n",
    "\n",
    "np.savetxt(\"nomask/vgg/pre_train7.txt\",feature_extraction_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32768)\n",
      "(500, 32768)\n",
      "(500, 32768)\n",
      "(500, 32768)\n",
      "(500, 32768)\n",
      "(500, 32768)\n",
      "(34, 32768)\n"
     ]
    }
   ],
   "source": [
    "dt_DenseNet1 = np.loadtxt('nomask/vgg/pre_train1.txt')\n",
    "dt_DenseNet2 = np.loadtxt('nomask/vgg/pre_train2.txt')\n",
    "dt_DenseNet3 = np.loadtxt('nomask/vgg/pre_train3.txt')\n",
    "dt_DenseNet4 = np.loadtxt('nomask/vgg/pre_train4.txt')\n",
    "dt_DenseNet5 = np.loadtxt('nomask/vgg/pre_train5.txt')\n",
    "dt_DenseNet6 = np.loadtxt('nomask/vgg/pre_train6.txt')\n",
    "dt_DenseNet7 = np.loadtxt('nomask/vgg/pre_train7.txt')\n",
    "\n",
    "DenseNet_full = [dt_DenseNet1,dt_DenseNet2,dt_DenseNet3,dt_DenseNet4,dt_DenseNet5,dt_DenseNet6,dt_DenseNet7]\n",
    "\n",
    "for i in DenseNet_full:print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concat = np.concatenate((dt_DenseNet1, dt_DenseNet2, dt_DenseNet3, dt_DenseNet4, dt_DenseNet5, dt_DenseNet6), axis=0)\n",
    "np.savetxt(\"nomask/vgg/vgg_full_data.txt\",train_concat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
